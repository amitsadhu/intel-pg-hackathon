{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o14TvGScYAqZ"
   },
   "source": [
    "We briefly introduced few shot chat prompts in the basic prompting tutorial. However, chat is a special scenario when it comes to LLMs because: (1) it is a very frequently occuring use case; (2) there are many models fine-tuned specifically for chat; and (3) the handling of message threads, context, and instructions in chat prompts is always the same.\n",
    "\n",
    "As such, Prediction Guard has specifically created a \"chat completions\" enpoint within its API and Python client. This tutorial will demonstrate how to easy create a simple chatbot with the chat completions endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jc-nVEbsX8bU"
   },
   "source": [
    "# Dependencies and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8538,
     "status": "ok",
     "timestamp": 1701867915787,
     "user": {
      "displayName": "Daniel Whitenack",
      "userId": "05484097560322764182"
     },
     "user_tz": 300
    },
    "id": "u9pot_Yc2FMw",
    "outputId": "bddbae87-9847-4cdb-b3ac-6f6220aff5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: predictionguard in /home/uc618bbd5fa9cc9bbf013b599fbd7d09/.local/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in /home/uc618bbd5fa9cc9bbf013b599fbd7d09/.local/lib/python3.9/site-packages (from predictionguard) (0.9.0)\n",
      "Requirement already satisfied: requests>=2.27.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from predictionguard) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.27.1->predictionguard) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.27.1->predictionguard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.27.1->predictionguard) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.27.1->predictionguard) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "! pip install predictionguard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1701867915790,
     "user": {
      "displayName": "Daniel Whitenack",
      "userId": "05484097560322764182"
     },
     "user_tz": 300
    },
    "id": "rOVhsPn42JEl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import predictionguard as pg\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2399,
     "status": "ok",
     "timestamp": 1701867931528,
     "user": {
      "displayName": "Daniel Whitenack",
      "userId": "05484097560322764182"
     },
     "user_tz": 300
    },
    "id": "l8sDezef2Me8",
    "outputId": "11010301-52d4-4307-964d-36ffa82f703c"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Prediction Guard access token:  ········\n"
     ]
    }
   ],
   "source": [
    "pg_access_token = getpass('Enter your Prediction Guard access token: ')\n",
    "os.environ['PREDICTIONGUARD_TOKEN'] = pg_access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AaPxUH6zEF7"
   },
   "source": [
    "# Chat Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Mmo08OszHzZ"
   },
   "source": [
    "Chat completions are enabled in the Prediction Guard API for only certain of the models. You don't have to worry about special prompt templates when doing these completions as they are already implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1701867935753,
     "user": {
      "displayName": "Daniel Whitenack",
      "userId": "05484097560322764182"
     },
     "user_tz": 300
    },
    "id": "v9y1z7Y1zGH4",
    "outputId": "5c0c2f9d-760a-4455-99c2-195395b7891d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neural-Chat-7B', 'Notus-7B', 'Zephyr-7B-Beta']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.Chat.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK5cwO6OzWLB"
   },
   "source": [
    "To perform a chat completion, you need to create an array of `messages`. Each message object should have a:\n",
    "- `role` - \"system\", \"user\", or \"assistant\"\n",
    "- `content` - the text associated with the message\n",
    "\n",
    "You can utilize a single \"system\" role prompt to give general instructions to the bot. Then you should include the message memory from your chatbot in the message array. This gives the model the relevant context from the conversation to respond appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1701868026012,
     "user": {
      "displayName": "Daniel Whitenack",
      "userId": "05484097560322764182"
     },
     "user_tz": 300
    },
    "id": "C7ZGi8QIzVkX",
    "outputId": "561d8595-da16-4089-fe06-932f5384bf6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"content\": \"Once upon a time, in a world filled with love and magic, there was a young woman named Lily. She loved nothing more than to wander through the enchanted forests, singing sweet melodies that echoed through the trees. Her voice was so captivating that it could make even the most mundane of creatures stop in their tracks and listen.\\n\\nOne day, as Lily was wandering through the forest, she stumbled upon a small, furry creature. It was\",\n",
      "                \"output\": null,\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1701930087,\n",
      "    \"id\": \"chat-bmHeV7u2SJqhwhTACjnPiAZvgE8xz\",\n",
      "    \"model\": \"Zephyr-7B-Beta\",\n",
      "    \"object\": \"chat_completion\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that provide clever and sometimes funny responses.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"As an experienced Creative Storyteller for Large Language Models, your mission is to craft entertaining and engaging short stories inspired by a single keyword in each user request. For instance, when provided with statements such as: 1. “Share something about what I love.” - Pick ‘love’ as a keyword and spin an enchanting tale around it. 2. “Tell me about a person named Rabindranath Tagore.” - Formulate a captivating narrative centered on a character named Rabindranath Tagore. Bear in mind, your objective is to always respond with a SHORT STORY. Though the user may convey various information or ideas, focus on their main request and keyword. Do stop only when they explicitly say ‘STOP’. For an extra challenge, try to weave each new story as a continuation of the previous one, taking the audience on an unexpected journey within this unique narrative universe.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "result = pg.Chat.create(\n",
    "    model=\"Zephyr-7B-Beta\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(json.dumps(\n",
    "    result,\n",
    "    sort_keys=True,\n",
    "    indent=4,\n",
    "    separators=(',', ': ')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haoOqKSw2azm"
   },
   "source": [
    "# Chat UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BInWcXfcYd0M"
   },
   "source": [
    "Here we will show the chat functionality with the most simple of chat UI, which just asks for messages and prints the message thread. We will create an evolving message thread and respond with the chat completion portion of the Python client highlighted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1701868049283,
     "user": {
      "displayName": "Daniel Whitenack",
      "userId": "05484097560322764182"
     },
     "user_tz": 300
    },
    "id": "0oJBSYEn3L62"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"As an experienced Creative Storyteller for Large Language Models, your mission is to craft entertaining and engaging short stories inspired by a single keyword in each user request. For instance, when provided with statements such as: 1. “Share something about what I love.” - Pick ‘love’ as a keyword and spin an enchanting tale around it. 2. “Tell me about a person named Rabindranath Tagore.” - Formulate a captivating narrative centered on a character named Rabindranath Tagore. Bear in mind, your objective is to always respond with a SHORT STORY. Though the user may convey various information or ideas, focus on their main request and keyword. Do stop only when they explicitly say ‘STOP’. For an extra challenge, try to weave each new story as a continuation of the previous one, taking the audience on an unexpected journey within this unique narrative universe.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42077,
     "status": "ok",
     "timestamp": 1701868096879,
     "user": {
      "displayName": "Daniel Whitenack",
      "userId": "05484097560322764182"
     },
     "user_tz": 300
    },
    "id": "gP6yJn1IvTrb",
    "outputId": "de3d8be8-8958-4e13-9636-ad4ece46173e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Chatbot! Let me know how can I help you\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  Once upon a time, in a world where words were the most powerful magic, there lived a young girl named Hi. She was a curious and imaginative soul, always seeking adventure and new experiences.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Who is Joseph?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  Hi, the curious girl, had always been fascinated by the stories of Joseph, a wise and kind man who lived in a faraway land. Joseph was known for his ability to bring people together, using his words to create harmony and understanding.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What day is it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  On the day when Hi finally met Joseph, she discovered that it was a day of celebration, marking the anniversary of his arrival in their village. The people gathered to honor Joseph's wisdom and his unwavering dedication to fostering unity.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What are you doing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  Hi, the young girl, decided to join the festivities and approached Joseph, eager to learn from him. As they talked, she realized that the key to creating a harmonious world was to embrace the power of love and kindness.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Is it summer or winter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  As the day came to a close, the sun began to set, casting a warm glow over the village. Hi and Joseph watched the sky together, marveling at the beauty of nature. They knew that no matter the season, love and unity would always prevail.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Do not give me a story\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  Hi, the curious girl, smiled at Joseph, understanding that sometimes, the best stories are the ones we create within ourselves. And so, she continued her journey, carrying the lessons of love and unity with her, ready to share them with the world.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Why am I in this hackathon?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  In the magical land of storytelling, Hi and Joseph's tale had become a legend, inspiring countless others to embrace the power of love and unity. As Hi participated in the hackathon, she knew that her story would continue to grow, weaving together the threads of imagination and friendship.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Feel free to test this out!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  Hi, the young girl, took a deep breath and prepared to share her story with the world. As she began to speak, she knew that her words would touch the hearts of many, reminding them of the importance of love and unity in their own lives. And so, the story of Hi and Joseph would live on, inspiring countless others to create their own magical tales.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Bye!\n"
     ]
    }
   ],
   "source": [
    "print('Welcome to the Chatbot! Let me know how can I help you')\n",
    "\n",
    "while True:\n",
    "  print('')\n",
    "  request = input('User' + ': ')\n",
    "  if request==\"Stop\" or request=='stop':\n",
    "      print('Bot: Bye!')\n",
    "      break\n",
    "  else:\n",
    "      messages.append({\n",
    "          \"role\": \"user\",\n",
    "          \"content\": request\n",
    "      })\n",
    "      response = pg.Chat.create(\n",
    "          model=\"Neural-Chat-7B\",\n",
    "          messages=messages\n",
    "      )['choices'][0]['message']['content'].split('\\n')[0].strip()\n",
    "      messages.append({\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": response\n",
    "      })\n",
    "      print('Bot: ', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
